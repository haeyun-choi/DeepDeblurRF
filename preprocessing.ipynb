{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepDeblurRF-G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Deblurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\haeyu\\downloads\\deepdeblurrf\\nafnet\\basicsr\\models\\base_model.py:276: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  load_net = torch.load(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " load net keys <built-in method keys of collections.OrderedDict object at 0x000002237FB4C940>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 08:49:42,887 INFO: Model [ImageRestorationModel] is created.\n"
     ]
    }
   ],
   "source": [
    "scene_type = \"motion_dbnerf_real\"  ################################ MODIFY THIS LINE -> \"motion\" or \"motion_dbnerf_real\", \"defocus\", \"defocus_dbnerf_real\" \n",
    "opt_path = f\"./NAFNet/options/test/DDRF_G/{scene_type}/SD_NAFNet-width32.yml\"\n",
    "\n",
    "from basicsr.models import create_model\n",
    "from basicsr.utils.options import parse\n",
    "from basicsr.utils import img2tensor as _img2tensor, tensor2img, imwrite\n",
    "\n",
    "opt = parse(opt_path, is_train=False)\n",
    "opt['dist'] = False\n",
    "NAFNet = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def img2tensor(img, bgr2rgb=False, float32=True):\n",
    "    img = img.astype(np.float32) / 255.\n",
    "    return _img2tensor(img, bgr2rgb=bgr2rgb, float32=float32)\n",
    "\n",
    "def display(img1, img2):\n",
    "    fig = plt.figure(figsize=(25, 10))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title('Input image', fontsize=16)\n",
    "    ax1.axis('off')\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.set_title('NAFNet output', fontsize=16)\n",
    "    ax2.axis('off')\n",
    "    ax1.imshow(img1)\n",
    "    ax2.imshow(img2)\n",
    "\n",
    "def single_image_inference(model, img, save_path):\n",
    "    model.feed_data(data={'lq': img.unsqueeze(dim=0)})\n",
    "    if model.opt['val'].get('grids', False):\n",
    "        model.grids()\n",
    "    model.test()\n",
    "    if model.opt['val'].get('grids', False):\n",
    "        model.grids_inverse()\n",
    "    visuals = model.get_current_visuals()\n",
    "    sr_img = tensor2img([visuals['result']])\n",
    "    imwrite(sr_img, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "scene_name = \"blurball\" ################################ MODIFY THIS LINE \n",
    "index = 0\n",
    "\n",
    "input_path = f'./data/{scene_name}/blur'\n",
    "output_path = f'./data/{scene_name}/deblur/deblur_{index}'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_path):\n",
    "    if filename.endswith('.png') or filename.endswith('.jpg'):\n",
    "        core_name = filename[:-4]\n",
    "        img_input = imread(os.path.join(input_path, filename))\n",
    "        inp = img2tensor(img_input)\n",
    "        img_output_path = os.path.join(output_path, core_name + '.png')\n",
    "        single_image_inference(NAFNet, inp, img_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "rf_path = f'./data/{scene_name}/rf/rf_{index}'\n",
    "rf_images_path = os.path.join(rf_path, 'images')\n",
    "os.makedirs(rf_images_path, exist_ok=True)\n",
    "\n",
    "# Copy deblur_0 images\n",
    "deblur_path = f'./data/{scene_name}/deblur/deblur_{index}'\n",
    "for f in os.listdir(deblur_path):\n",
    "    shutil.copy2(os.path.join(deblur_path, f), os.path.join(rf_images_path, f))\n",
    "\n",
    "# Copy nv images\n",
    "nv_path = f'./data/{scene_name}/nv'\n",
    "for f in os.listdir(nv_path):\n",
    "    shutil.copy2(os.path.join(nv_path, f), os.path.join(rf_images_path, f))\n",
    "\n",
    "# Copy hold file\n",
    "for f in os.listdir(f'./data/{scene_name}'):\n",
    "    if f.startswith('hold'):\n",
    "        shutil.copy2(os.path.join(f'./data/{scene_name}', f), os.path.join(rf_path, f))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched basicsr_RF → basicsr (for RF-guided deblurring)\n"
     ]
    }
   ],
   "source": [
    "# Restore basicsr_RF\n",
    "nafnet_dir = \"./NAFNet\"\n",
    "if os.path.exists(os.path.join(nafnet_dir, \"basicsr\")):\n",
    "    os.rename(os.path.join(nafnet_dir, \"basicsr\"), os.path.join(nafnet_dir, \"basicsr_SD\"))\n",
    "os.rename(os.path.join(nafnet_dir, \"basicsr_RF\"), os.path.join(nafnet_dir, \"basicsr\"))\n",
    "print(\"Switched basicsr_RF → basicsr (for RF-guided deblurring)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Proceed to `ddrf.py`\n",
    "\n",
    "The initial preprocessing steps are now complete.\n",
    "\n",
    "You can now run the main DDRF pipeline using:\n",
    "\n",
    "```bash\n",
    "python ddrf.py -c configs/<data_type>/<blur_type>or<None>/<scene_name>.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddrf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
